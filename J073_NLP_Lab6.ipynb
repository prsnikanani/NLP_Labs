{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-01T14:06:34.634016Z","iopub.status.busy":"2024-09-01T14:06:34.633499Z","iopub.status.idle":"2024-09-01T14:06:34.995165Z","shell.execute_reply":"2024-09-01T14:06:34.994326Z","shell.execute_reply.started":"2024-09-01T14:06:34.633981Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/stanford-question-answering-dataset/train-v1.1.json\n","/kaggle/input/stanford-question-answering-dataset/dev-v1.1.json\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-09-01T14:30:01.394495Z","iopub.status.busy":"2024-09-01T14:30:01.393607Z","iopub.status.idle":"2024-09-01T14:30:06.596180Z","shell.execute_reply":"2024-09-01T14:30:06.595436Z","shell.execute_reply.started":"2024-09-01T14:30:01.394439Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"79f1cef66f1345ef8e6eaed8af1f7bcb","version_major":2,"version_minor":0},"text/plain":["Downloading readme:   0%|          | 0.00/7.62k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e90f3c3e0a4e4add8fcf9ab864729799","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"15263b69d9be425593f7206b5e195328","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/1.82M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1a58793d1eb5491abf548564599d37dd","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/87599 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"76a2bde8854640268d09775aafc8608b","version_major":2,"version_minor":0},"text/plain":["Generating validation split:   0%|          | 0/10570 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from datasets import load_dataset\n","\n","squad = load_dataset(\"squad\", split=\"train[:5000]\")"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-09-01T14:30:06.598109Z","iopub.status.busy":"2024-09-01T14:30:06.597773Z","iopub.status.idle":"2024-09-01T14:30:06.615501Z","shell.execute_reply":"2024-09-01T14:30:06.614620Z","shell.execute_reply.started":"2024-09-01T14:30:06.598071Z"},"trusted":true},"outputs":[],"source":["squad = squad.train_test_split(test_size=0.2)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-09-01T14:30:45.272430Z","iopub.status.busy":"2024-09-01T14:30:45.272054Z","iopub.status.idle":"2024-09-01T14:30:46.552479Z","shell.execute_reply":"2024-09-01T14:30:46.551525Z","shell.execute_reply.started":"2024-09-01T14:30:45.272397Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a883d26339fd449fadb6943a3b6e1b6a","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3a4c923f652a4c51990eed90ac2949a7","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f60edb7189f24aa597a539a6b493a414","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7c87e5db731c4546a452d936a11dfb89","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]}],"source":["from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-09-01T14:31:34.709382Z","iopub.status.busy":"2024-09-01T14:31:34.708437Z","iopub.status.idle":"2024-09-01T14:31:34.719609Z","shell.execute_reply":"2024-09-01T14:31:34.718713Z","shell.execute_reply.started":"2024-09-01T14:31:34.709337Z"},"trusted":true},"outputs":[],"source":["def preprocess_function(examples):\n","    questions = [q.strip() for q in examples[\"question\"]]\n","    inputs = tokenizer(\n","        questions,\n","        examples[\"context\"],\n","        max_length=384,\n","        truncation=\"only_second\",\n","        return_offsets_mapping=True,\n","        padding=\"max_length\",\n","    )\n","\n","    offset_mapping = inputs.pop(\"offset_mapping\")\n","    answers = examples[\"answers\"]\n","    start_positions = []\n","    end_positions = []\n","\n","    for i, offset in enumerate(offset_mapping):\n","        answer = answers[i]\n","        start_char = answer[\"answer_start\"][0]\n","        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n","        sequence_ids = inputs.sequence_ids(i)\n","\n","        \n","        idx = 0\n","        while sequence_ids[idx] != 1:\n","            idx += 1\n","        context_start = idx\n","        while sequence_ids[idx] == 1:\n","            idx += 1\n","        context_end = idx - 1\n","\n","        \n","        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n","            start_positions.append(0)\n","            end_positions.append(0)\n","        else:\n","            \n","            idx = context_start\n","            while idx <= context_end and offset[idx][0] <= start_char:\n","                idx += 1\n","            start_positions.append(idx - 1)\n","\n","            idx = context_end\n","            while idx >= context_start and offset[idx][1] >= end_char:\n","                idx -= 1\n","            end_positions.append(idx + 1)\n","\n","    inputs[\"start_positions\"] = start_positions\n","    inputs[\"end_positions\"] = end_positions\n","    return inputs"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-09-01T14:32:07.750392Z","iopub.status.busy":"2024-09-01T14:32:07.750015Z","iopub.status.idle":"2024-09-01T14:32:10.731127Z","shell.execute_reply":"2024-09-01T14:32:10.730108Z","shell.execute_reply.started":"2024-09-01T14:32:07.750355Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9f4ae36548d84f1b9f7403013c14e2b2","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8e5ab7bea337428494dda993476fd752","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenized_squad = squad.map(preprocess_function, batched=True, remove_columns=squad[\"train\"].column_names)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-09-01T14:33:38.514893Z","iopub.status.busy":"2024-09-01T14:33:38.514476Z","iopub.status.idle":"2024-09-01T14:33:38.519461Z","shell.execute_reply":"2024-09-01T14:33:38.518541Z","shell.execute_reply.started":"2024-09-01T14:33:38.514854Z"},"trusted":true},"outputs":[],"source":["from transformers import DefaultDataCollator\n","\n","data_collator = DefaultDataCollator()"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-09-01T14:33:46.669931Z","iopub.status.busy":"2024-09-01T14:33:46.669510Z","iopub.status.idle":"2024-09-01T14:33:47.954917Z","shell.execute_reply":"2024-09-01T14:33:47.953968Z","shell.execute_reply.started":"2024-09-01T14:33:46.669893Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e422f71186e540cb9437cb2e5b85d2c5","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n","\n","model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert/distilbert-base-uncased\")"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-09-01T14:46:03.933206Z","iopub.status.busy":"2024-09-01T14:46:03.932318Z","iopub.status.idle":"2024-09-01T14:53:26.887915Z","shell.execute_reply":"2024-09-01T14:53:26.886963Z","shell.execute_reply.started":"2024-09-01T14:46:03.933164Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1250/1250 07:21, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Token Level Iou</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>1.630697</td>\n","      <td>0.526942</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.040400</td>\n","      <td>1.729835</td>\n","      <td>0.542635</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>1.040400</td>\n","      <td>1.671823</td>\n","      <td>0.548313</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.586200</td>\n","      <td>1.825051</td>\n","      <td>0.546232</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.586200</td>\n","      <td>1.871797</td>\n","      <td>0.550826</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=1250, training_loss=0.7386638549804687, metrics={'train_runtime': 442.2205, 'train_samples_per_second': 45.226, 'train_steps_per_second': 2.827, 'total_flos': 1959796500480000.0, 'train_loss': 0.7386638549804687, 'epoch': 5.0})"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","os.environ[\"WANDB_DISABLED\"] = \"true\"  \n","\n","training_args = TrainingArguments(\n","    output_dir=\"./my_awesome_qa_model\",\n","    eval_strategy=\"epoch\",  \n","    learning_rate=2e-5,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    num_train_epochs=5,\n","    weight_decay=0.01,\n","    logging_dir=\"./logs\",   \n","    save_total_limit=1\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_squad[\"train\"],\n","    eval_dataset=tokenized_squad[\"test\"],  \n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics \n",")\n","\n","\n","trainer.train()\n"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-09-01T14:53:35.770055Z","iopub.status.busy":"2024-09-01T14:53:35.769312Z","iopub.status.idle":"2024-09-01T14:53:43.025452Z","shell.execute_reply":"2024-09-01T14:53:43.024505Z","shell.execute_reply.started":"2024-09-01T14:53:35.770013Z"},"trusted":true},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='126' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [63/63 00:27]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Evaluation results: {'eval_loss': 1.8717974424362183, 'eval_token_level_iou': 0.5508263698992213, 'eval_runtime': 7.2469, 'eval_samples_per_second': 137.989, 'eval_steps_per_second': 8.693, 'epoch': 5.0}\n"]}],"source":["eval_results = trainer.evaluate()\n","print(f\"Evaluation results: {eval_results}\")\n"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-09-01T14:53:56.148719Z","iopub.status.busy":"2024-09-01T14:53:56.147752Z","iopub.status.idle":"2024-09-01T14:54:03.389705Z","shell.execute_reply":"2024-09-01T14:54:03.388688Z","shell.execute_reply.started":"2024-09-01T14:53:56.148641Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Evaluation results with custom metric: {'eval_loss': 1.8717974424362183, 'eval_token_level_iou': 0.5508263698992213, 'eval_runtime': 7.2289, 'eval_samples_per_second': 138.335, 'eval_steps_per_second': 8.715, 'epoch': 5.0}\n"]}],"source":["def compute_token_level_iou(pred_start, pred_end, true_start, true_end):\n","    pred_tokens = set(range(pred_start, pred_end + 1))\n","    true_tokens = set(range(true_start, true_end + 1))\n","\n","    intersection = len(pred_tokens.intersection(true_tokens))\n","    union = len(pred_tokens.union(true_tokens))\n","\n","    iou = intersection / union if union != 0 else 0\n","    return iou\n","\n","def compute_metrics(eval_pred):\n","    start_preds, end_preds = eval_pred.predictions\n","    start_labels, end_labels = eval_pred.label_ids\n","\n","    ious = []\n","    for i in range(len(start_preds)):\n","        iou = compute_token_level_iou(\n","            start_preds[i].argmax(), end_preds[i].argmax(),\n","            start_labels[i], end_labels[i]\n","        )\n","        ious.append(iou)\n","\n","    mean_iou = sum(ious) / len(ious)\n","    return {\"token_level_iou\": mean_iou}\n","\n","eval_results = trainer.evaluate(metric_key_prefix=\"eval\")\n","print(f\"Evaluation results with custom metric: {eval_results}\")\n"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-09-01T14:55:39.415044Z","iopub.status.busy":"2024-09-01T14:55:39.414645Z","iopub.status.idle":"2024-09-01T14:55:39.444790Z","shell.execute_reply":"2024-09-01T14:55:39.443816Z","shell.execute_reply.started":"2024-09-01T14:55:39.415008Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Question: What is the name of the repository?\n","Answer: hugging face library\n"]}],"source":["def answer_question(question, context):\n","    inputs = tokenizer.encode_plus(question, context, return_tensors=\"pt\")\n","    \n","    inputs = {key: value.to(device) for key, value in inputs.items()}\n","    \n","    outputs = model(**inputs)\n","    answer_start = torch.argmax(outputs.start_logits)\n","    answer_end = torch.argmax(outputs.end_logits) + 1\n","\n","    input_ids = inputs[\"input_ids\"].tolist()[0]\n","    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n","    return answer\n","\n","\n","\n","question = \"What is the name of the repository?\"\n","context = \"The Hugging Face library provides an easy way to use transformer models.\"\n","answer = answer_question(question, context)\n","print(f\"Question: {question}\")\n","print(f\"Answer: {answer}\")\n"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-09-01T14:57:54.745332Z","iopub.status.busy":"2024-09-01T14:57:54.744955Z","iopub.status.idle":"2024-09-01T14:57:54.837430Z","shell.execute_reply":"2024-09-01T14:57:54.836458Z","shell.execute_reply.started":"2024-09-01T14:57:54.745295Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DistilBertForQuestionAnswering(\n","  (distilbert): DistilBertModel(\n","    (embeddings): Embeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (transformer): Transformer(\n","      (layer): ModuleList(\n","        (0-5): 6 x TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            (activation): GELUActivation()\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","      )\n","    )\n","  )\n","  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n","  (dropout): Dropout(p=0.1, inplace=False)\n",")"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model.to(device)\n"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-09-01T14:57:47.065822Z","iopub.status.busy":"2024-09-01T14:57:47.065172Z","iopub.status.idle":"2024-09-01T14:57:47.790453Z","shell.execute_reply":"2024-09-01T14:57:47.789596Z","shell.execute_reply.started":"2024-09-01T14:57:47.065781Z"},"trusted":true},"outputs":[{"data":{"text/plain":["('./my_awesome_qa_model/tokenizer_config.json',\n"," './my_awesome_qa_model/special_tokens_map.json',\n"," './my_awesome_qa_model/vocab.txt',\n"," './my_awesome_qa_model/added_tokens.json')"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["model.save_pretrained(\"./my_awesome_qa_model\")\n","tokenizer.save_pretrained(\"./my_awesome_qa_model\")\n"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-09-01T14:57:49.296169Z","iopub.status.busy":"2024-09-01T14:57:49.295272Z","iopub.status.idle":"2024-09-01T14:57:49.378630Z","shell.execute_reply":"2024-09-01T14:57:49.377904Z","shell.execute_reply.started":"2024-09-01T14:57:49.296127Z"},"trusted":true},"outputs":[],"source":["from transformers import DistilBertTokenizer, DistilBertForQuestionAnswering\n","\n","\n","tokenizer = DistilBertTokenizer.from_pretrained(\"./my_awesome_qa_model\")\n","model = DistilBertForQuestionAnswering.from_pretrained(\"./my_awesome_qa_model\")\n"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2024-09-01T15:01:02.349710Z","iopub.status.busy":"2024-09-01T15:01:02.349042Z","iopub.status.idle":"2024-09-01T15:01:02.366491Z","shell.execute_reply":"2024-09-01T15:01:02.365641Z","shell.execute_reply.started":"2024-09-01T15:01:02.349669Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Question: Which country contains the majority of the Amazon rainforest?\n","Answer: brazil\n"]}],"source":["question = \"Which country contains the majority of the Amazon rainforest?\"\n","context = \"The Amazon rainforest is the largest tropical rainforest in the world, with 60% of it located in Brazil.\"\n","answer = answer_question(question, context)\n","print(f\"Question: {question}\")\n","print(f\"Answer: {answer}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":374,"sourceId":799923,"sourceType":"datasetVersion"}],"dockerImageVersionId":30762,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
